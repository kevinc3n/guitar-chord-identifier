{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d60648a-f3cf-40a6-8871-07509fa8acfd",
   "metadata": {},
   "source": [
    "# Guitar Chord Model Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418eef9f-6615-42df-a695-e961885f4f31",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6580f308-2176-461f-95ef-cd1509ba639f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwave\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4a232-4934-4190-867e-ca0276bbc1a0",
   "metadata": {},
   "source": [
    "### Load the Model and Setup the Categorical Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a298a97-1523-4438-949a-279bc226708f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# LOAD THE MODEL HERE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_attempt_98_acc.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# LOAD THE MODEL HERE\n",
    "model = load_model('cnn_attempt_98_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d465b9f-171f-4641-b90e-b7cc7610b862",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SETUP THE CHORD LABELS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m      3\u001b[0m chords_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m chords_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(chords_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# SETUP THE CHORD LABELS\n",
    "label_encoder = LabelEncoder()\n",
    "chords_list = ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']\n",
    "chords_array = np.array(chords_list)\n",
    "y = label_encoder.fit_transform(chords_array)\n",
    "# PRINT THE CHORD OPTIONS\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e80012-3aec-4a9e-8979-6001c0cdeaeb",
   "metadata": {},
   "source": [
    "### Setup an Audio Recorder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe115ba5-a755-42ef-bb84-8502e7e4a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP AN AUDIO RECORDER\n",
    "class AudioRecorder:\n",
    "    def __init__(self, filename='recording.wav', chunk=1024, channels=1, rate=44100, threshold=2000, duration=2):\n",
    "        self.filename = filename\n",
    "        self.chunk = chunk\n",
    "        self.channels = channels\n",
    "        self.rate = rate\n",
    "        self.frames = []\n",
    "        self.threshold = threshold\n",
    "        self.duration = duration\n",
    "        self.pa = pyaudio.PyAudio()\n",
    "        self.stream = self.pa.open(format=pyaudio.paInt16,\n",
    "                                   channels=self.channels,\n",
    "                                   rate=self.rate,\n",
    "                                   input=True,\n",
    "                                   frames_per_buffer=self.chunk)\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def start_recording(self):\n",
    "        while True:\n",
    "            print(\"Listening for threshold level...\")\n",
    "            while True:\n",
    "                data = np.frombuffer(self.stream.read(self.chunk), dtype=np.int16)\n",
    "                if np.max(data) > self.threshold:\n",
    "                    print(\"Threshold level reached. Recording started...\")\n",
    "                    self.record()\n",
    "                    break\n",
    "\n",
    "    def record(self):\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < self.duration:\n",
    "            data = self.stream.read(self.chunk)\n",
    "            self.lock.acquire()\n",
    "            self.frames.append(data)\n",
    "            self.lock.release()\n",
    "        self.stop_recording()\n",
    "        self.frames.clear()\n",
    "        time.sleep(0.5)  # Wait for a moment before restarting recording\n",
    "\n",
    "    def stop_recording(self):\n",
    "        print(\"Recording stopped...\")\n",
    "        with wave.open(self.filename, 'wb') as wf:\n",
    "            wf.setnchannels(self.channels)\n",
    "            wf.setsampwidth(self.pa.get_sample_size(pyaudio.paInt16))\n",
    "            wf.setframerate(self.rate)\n",
    "            self.lock.acquire()\n",
    "            wf.writeframes(b''.join(self.frames))\n",
    "            self.lock.release()\n",
    "        print(f\"Recording saved as {self.filename}\")\n",
    "        self.predict(self.filename)\n",
    "\n",
    "    def predict(self, filename):\n",
    "        # LOAD THE AUDIO FILE\n",
    "        audio_file = filename  # Use the recorded WAV file\n",
    "        audio_sample, sr = librosa.load(audio_file)\n",
    "    \n",
    "        # PREPROCESS THE FEATURES OF THE AUDIO FILE\n",
    "        features = generate_features(audio_sample)\n",
    "    \n",
    "        # RESHAPE THE ARRAY TO MATCH THE EXPECTED INPUT SIZE OF THE MODEL\n",
    "        features = np.expand_dims(features, axis=0)\n",
    "    \n",
    "        # MAKE PREDICTION\n",
    "        predictions = model.predict(features)\n",
    "    \n",
    "        # GET THE PREDICTED CLASS\n",
    "        predicted_class = np.argmax(predictions)\n",
    "\n",
    "        # TRANSFORM IT INTO THE CHORD NAME\n",
    "        predicted_categorical_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "        # predicted_categorical_label HAS THE PREDICTED CHORD TYPE <- DISPLAY THIS ON THE PAGE\n",
    "    \n",
    "        # PRINT THE CHORD NAME\n",
    "        print(f\"For audio file {audio_file}, predicted class: {predicted_categorical_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fef97-880e-4fc7-9649-d4b932258b11",
   "metadata": {},
   "source": [
    "### Functions to Process the Live Recorded Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0220f1d-c358-44df-95bf-2aea7e46e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADS THE FEATURES IF THEY ARE SMALLER THAN THE EXPECTED SHAPE\n",
    "def padding(array, xx, yy):\n",
    "    \"\"\"\n",
    "    :param array: numpy array\n",
    "    :param xx: desired height\n",
    "    :param yy: desirex width\n",
    "    :return: padded array\n",
    "    \"\"\"\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "    a = max((xx - h) // 2,0)\n",
    "    aa = max(0,xx - a - h)\n",
    "    b = max(0,(yy - w) // 2)\n",
    "    bb = max(yy - b - w,0)\n",
    "    return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')\n",
    "\n",
    "# FUNCTION TO NORMALIZE A FEATURE\n",
    "def normalize(feature):\n",
    "    return (feature - np.min(feature)) / (np.max(feature) - np.min(feature))\n",
    "\n",
    "# EXTRACTS THE NEEDED FEATURES FROM AN AUDIO FILE\n",
    "def generate_features(audio_sample):\n",
    "    max_size = 1000\n",
    "    n_mfcc = 13\n",
    "    sr = 22050\n",
    "\n",
    "    # EXTRACT STFT, MFCCS, SPECTRAL CENTROID, CHROMA STFT, AND SPECTRAL BANDWIDTH\n",
    "    stft = librosa.stft(y=audio_sample, n_fft=255, hop_length=512)\n",
    "    stft = stft[:, :max_size]  # Truncate stft to max_size\n",
    "    stft = padding(np.abs(stft), 128, max_size)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=audio_sample, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs = mfccs[:, :max_size]  # Truncate mfccs to max_size\n",
    "    mfccs = padding(mfccs, 128, max_size)\n",
    "\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=audio_sample, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio_sample, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=audio_sample, sr=sr)\n",
    "\n",
    "    # TRUNCATE THE SIZE OF A FEATURE IF IT EXCEEDS MAX_SIZE (NEEDED FOR COMPUTATIONAL EFFICIENCY)\n",
    "    spec_bw_truncated = spec_bw[:, :max_size]\n",
    "    spec_centroid_truncated = spec_centroid[:, :max_size]\n",
    "    chroma_stft_truncated = chroma_stft[:, :max_size]\n",
    "\n",
    "    # CREATE THE IMAGE STACK\n",
    "    image = np.array([padding(normalize(spec_bw_truncated), 1, max_size)]).reshape(1, max_size)\n",
    "    image = np.append(image, padding(normalize(spec_centroid_truncated), 1, max_size), axis=0)\n",
    "\n",
    "    # THESE THREE FEATURES ARE BEING STACKED INTO ONE DIMENSION\n",
    "    for i in range(0, 9):\n",
    "        image = np.append(image, padding(normalize(spec_bw_truncated), 1, max_size), axis=0)\n",
    "        image = np.append(image, padding(normalize(spec_centroid_truncated), 1, max_size), axis=0)\n",
    "        image = np.append(image, padding(normalize(chroma_stft_truncated), 12, max_size), axis=0)\n",
    "\n",
    "    # STACK STFT AND MFCCS INTO THEIR OWN DIMENSION\n",
    "    image = np.dstack((image, stft))\n",
    "    image = np.dstack((image, mfccs))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf7fa7-76ea-4c90-bf14-c5337e5dbb5c",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae462d7-f525-40d8-aee9-5bbf68a3a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "For audio file recording.wav, predicted class: e\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "For audio file recording.wav, predicted class: e\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "For audio file recording.wav, predicted class: a\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "For audio file recording.wav, predicted class: a\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "For audio file recording.wav, predicted class: a\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "For audio file recording.wav, predicted class: a\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "For audio file recording.wav, predicted class: g\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "For audio file recording.wav, predicted class: g\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "For audio file recording.wav, predicted class: a\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "For audio file recording.wav, predicted class: am\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n",
      "Recording stopped...\n",
      "Recording saved as recording.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "For audio file recording.wav, predicted class: c\n",
      "Listening for threshold level...\n",
      "Threshold level reached. Recording started...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     recorder\u001b[38;5;241m.\u001b[39mstart_recording()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m recorder \u001b[38;5;241m=\u001b[39m AudioRecorder(filename)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# START A LIVE RECORDING FEED\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m recorder\u001b[38;5;241m.\u001b[39mstart_recording()\n",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m, in \u001b[0;36mAudioRecorder.start_recording\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold level reached. Recording started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m, in \u001b[0;36mAudioRecorder.record\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration:\n\u001b[1;32m---> 54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filename = 'recording.wav'\n",
    "    recorder = AudioRecorder(filename)\n",
    "\n",
    "    # START A LIVE RECORDING FEED\n",
    "    recorder.start_recording()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e09ac-980d-461d-b35a-62c0a67f1e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
